\documentclass[compsoc,conference,a4paper,10pt,times]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
% \usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts, amsthm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{bmpsize}
\usepackage{xcolor}
\usepackage{lipsum}
% \usepackage[colorlinks=true,urlcolor=black,pdftitle="Type Flattening Obfuscation"]{hyperref}
\usepackage{hyperref}
\hypersetup{
  colorlinks = true,
  urlcolor = black,
  pdftitle = "A Lightweight Ofuscation for Function Signature Flattening",
  pdfauthor = "Ta Thanh Dinh"
}
\usepackage{tikz-cd}
\usepackage{listings}
\lstset{
  basicstyle=\small\ttfamily,
  showspaces=false,
  frame=tb,
  tabsize=2,
  frame=single,
  captionpos=b,
}
% \lstloadlanguages{C,C++,[x86masm]Assembler}
% \lstloadlanguages{C}
% \lstset{
%   morekeywords={signed32}
% }
\lstdefinestyle{c}{
  language=C,
  morekeywords={signed32}
}
\usepackage{cleveref}
\usepackage[strict]{changepage}
\usepackage{rotating}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage[sorting=ynt,sortcites=true,backend=bibtex8,doi=false,maxnames=6,isbn=false,firstinits=true]{biblatex}
\addbibresource{reference}

\newtheorem{definition}{Definition}

\begin{document}

\title{A Lightweight Ofuscation for Function Signature Flattening}

\author{\IEEEauthorblockN{Ta Thanh Dinh}
\IEEEauthorblockA{tathanhdinh@gmail.com}}

\maketitle

\begin{abstract}
  Beside data and control flow, high-level types are important in binary code analysis, particularly in
  decompilation. Some research papers have introduced methods to map machine-dependent objects into types
  of some C-like type system. For the obfuscation/anti-decompilation purpose, we
  present a technique which bypasses existing type recovery approaches. We have implemented a
  prototype obfuscating C compiler to demonstrate the technique, the compiler is
  given open source.
\end{abstract}

\begin{IEEEkeywords}
type recovery, decompilation, obfuscation
\end{IEEEkeywords}

\section{Introduction}
\noindent
Binary code \emph{decompilation}~\cite{cifuentes_reverse_1994} is to transform the low-level,
machine-dependent code of a program into a high-level form, like code of a high-level language.
In almost all academic research papers and commerical products, the target language is C.
Similar to compilers, a modern binary code decompiler consists of many
phases~\cite{cifuentes_reverse_1994,van_emmerik_static_2007}: disassembly, function boundary detection, immediate
representation (IR) lifting, control-flow graph (CFG) recovery, high-level variables detection,
type (i.e. variable types and function signatures) recovery, etc. Each phase requires
particular but not independent~\cite{schwarz_disassembly_2002} analysis techniques: the results of
one can affect another. The analyzed program is
transformed gradually into a higher-level, more abstract and more understandable representation.

On the contrary, binary code \emph{obfuscation} protects the machine code from
being decompiled, or from being analyzed in general. Because the analysis contains of different
interdependent phases, the obfuscation may attack any of them, e.g. anti-disassembly
(binary packer, self-modifying code), binary stripping, control-flow flattening, virtualization (for both
data and control obfuscation)... just name a few. Basically, each obfuscation method consists of one or
several \emph{potent transformations}~\cite{collberg_surreptitious_2009,dalla_preda_semantic-based_2005}
that hide certain properties of the code.

\subsubsection*{Context and problem}
An optional feature of binary code decompilation is \emph{type reconstruction}, namely to recover high-level types from machine-dependent
objects~\cite{mycroft_type-based_1999, van_emmerik_static_2007}. This is the research objective of some
research papers~\cite{lee_tie_2011,elwazeer_scalable_2013,robbins_minx_2016,noonan_polymorphic_2016},
and killing feature of commercial~\cite{noauthor_hex-rays_nodate,noauthor_jeb_nodate}
as well as open source~\cite{noauthor_ghidra_nodate} binary code analysis tools. Beside decompilation,
types and particularly \emph{function signatures} are also essential in numerous applications,
e.g. static binary rewriting~\cite{bernat_anywhere_2011,anand_compiler-level_2013} and
raising~\cite{yadavalli_raising_2019,goodman_lifting_2018},
see for example~\cite{caballero_type_2016} for a more completed list. Thus the knowledge about types
expand the attack surface since more analysis can be applied on the programs.

\subsubsection*{Contribution}
Despite of successes in binary type reconstruction and the need of protecting function signatures, to the best
of our knowledge there is no explicit effort in hiding type information. This paper presents a method
for type obfuscation, the principal idea is based on the fact that the compiler does not need to preserve all information
about high-level types (type erasure), then with specific tricks we can exploit the \emph{semantics gap} between
the high-level language and machine code to make some information very hard if not impossible
to be recovered. We do not claim that all type information can be hidden, the attacker can
eventually know some but it would be hard to distinguish the concrete underlying types from one to another,
thus the proposed notion of \emph{type flattening}.

We implement the tricks in \emph{uCc}~\cite{ta_ucc_nodate}, an open source obfuscating C compiler which obfuscates
function signatures. The functions in binaries generated by \emph{uCc} can be
perfectly analyzed by classical procedures (boundary detection, disassembling, CFG recovery, etc),
only their signatures are obfuscated. That way, we can evaluate the effectiveness of type
obfuscation tricks on function signatures while excluding unwanted obfuscation effects that may come from (bad) results
of other analysis phases.
We find that Mixed Boolean Arithmetic (MBA)
expressions~\cite{eyrolles_obfuscation_2017,zhou_information_2007} are a good match for the goal.

% \subsection*{Contributions}
% \noindent
In summary, our contributions are as follows:
\begin{itemize}
  \item We introduce the notion of \emph{type flattening}, it aims at protecting a high-level
  property (types) of the program in contrast with classical methods which focus on lower
  properties as data or control flow.

  \item We implement an open source prototype compiler \emph{uCc} to realize the ideas of obfuscation.
  We introduce in \emph{uCc} a simple method to generate pointer aliases which would be hard to reverse
  thanks to the resilience of MBA obfuscation~\cite{eyrolles_defeating_2016,biondi_effectiveness_2017}.

  \item We give also an implementation for the permutation polynomials
  of MBA while other open source state-of-the-art obfuscators
  (e.g. Tigress~\cite{noauthor_tigress_nodate}) give only basic arithmetic encoding expressions.
  Other deobfuscation tools (e.g. Syntia~\cite{blazytko_syntia_2017}, QSynth~\cite{david_qsynth_2020})
  can profit from \emph{uCc} to test their capabilities of MBA simplification.

  \item We evaluate the binaries generated by \emph{uCc} against decent decompilers, the results
  show that no one can detect correctly the underlying types of arguments on function signatures: the
  original types are indistinguishable from the highest types in the C's integer conversion rank.
\end{itemize}

\section{Brief history of binary type inference}
\noindent
In statically typed languages, the compiler does not need preserve source code level type information in
the generated machine code (type erasure), then type recovering requires special techniques. Before
presenting the type flattening obfuscation, we give a brief discussion about how current methods on binary type
inference work, that gives some intuition about our bypassing techniques.
%  which will be presented in the next section.

Though a broad survey for research
up until 2015 has been given in~\cite{caballero_type_2016}, it sustains a storage point of view bias: types are attached
always with concrete storage primitives (e.g. registers, memory), there are no essential differences between types and
data structures, so are the techniques to recover them. Actually, types are compile-time constraints, they
may or may not have runtime storage imprints. An example is C's \emph{type qualifier} (e.g.
\texttt{const}, \texttt{restrict}), in general any
\emph{refinement type} should not leave storage traces, the same thing with generics. More concretely, as
we will present in the section, the \emph{low-level polymorphism} is a very specific problem that binary type
recovery techniques have to deal with.
Also, the survey lacks some important
papers which are only published until later~\cite{noonan_polymorphic_2016,robbins_minx_2016}.

We focus only on semantics-based approaches, recent research using machine learning~\cite{maier_typeminer_2019}
or statistical language model~\cite{katz_estimating_2016} are out of scope of the paper.
We omit the phase of variable/function detection, which is an essential step before
type recovering, more details on this subject can be referenced in~\cite{balakrishnan_divine_2007}.
We avoid also difficulties in disassembling, the binaries are supposed to be perfectly disassemblable.

\subsubsection*{Setting} From now on, unless otherwise stated, the target language is C.
We use a strong version of the type system of C where implicit conversions are disabled, basically
it is a type system obtained by
\begin{center}
  \texttt{gcc -Werror -Wconversion}
\end{center}
% This is also the target almost all research papers and tools in the domain.

\subsection{Initial work}
\noindent
Though earlier ideas have been proposed in another context~\cite{shivers_data-flow_1990},
the research in recovering types from low-level languages may begin with the classic paper of
Mycroft~\cite{mycroft_type-based_1999} for his interest of decompilation. The principal idea is
inspired by the work of Damas-Hindley-Milner~\cite{milner_theory_1978,hindley_principal_1969,damas_principal_1982} in
the ML language: types of variables and functions are checked/referenced automatically
from how they are used in the program's source code. For example, given an expression
\begin{equation*}
  x + y
\end{equation*}
then at least $x$ or $y$ must have integer type, it is impossible that both of them are pointers
since adding two pointers does not type check.

The method of Mycroft has several limits, as pointed out by Van Emmerik~\cite{van_emmerik_static_2007}.
One of them comes from the fact that the low-level languages take care mostly on the value of
the computation, then (the result of) an expression can be used in several ways and it behaves as
different types (low-level polymorphism). Let's consider an assignment
\begin{equation*}
  p' = p + n
\end{equation*}
where $\vdash p \colon \mathtt{ptr}(S)$ ($p$ is of type pointer to a struct $S$) and
$\vdash n \colon \mathtt{int}$, Mycroft's
rules derive $\vdash p' \colon \mathtt{ptr}(S)$ since $p + n$ is considered as the offset calculation to
access some element of an array of $S$. But $p + n$ can be also an
offset calculation to access some field of type, e.g. $\mathtt{int}$, of the struct $S$,
then $\vdash p' \colon \mathtt{ptr}(\mathtt{int})$.

To overcome these problems, Van Emmerik has proposed a \emph{data-flow based}
(in contrast with Mycroft's \emph{constraint based}) approach where type information of an object will be refined gradually,
instead of binding it early to some fixed type. He proposed using \emph{subtype lattices} to express the
preciseness of type information:
\begin{figure}[h]
  \centering
  \begin{tikzcd}
    & \mathtt{void*} \arrow{dl}[sloped,above]{<\colon} \arrow{dr}[sloped, above]{\colon>} & \\
    \mathtt{ptr}(S) & & \mathtt{ptr}(\mathtt{int})
  \end{tikzcd}
  \caption{A subtype lattice}
\end{figure}
$p'$ will not be early bound as $\mathtt{ptr}(S)$, instead $\vdash p' \colon \mathtt{void*}$
(adding integer to pointer does not always result in pointer of the same type) and
$\mathtt{ptr}(S) <\colon \mathtt{void*}$. The precise type
is only assigned later, when enough constraints are derived from other uses, e.g.:
\begin{equation*}
  *{p'} = m
\end{equation*}
where $\vdash m \colon \mathtt{int}$, it then derives $\vdash p' \colon \mathtt{ptr}(\mathtt{int})$,
finally $\vdash p' \colon \mathtt{ptr}(\mathtt{int})$ since
$\mathtt{ptr}(\mathtt{int}) = \mathtt{ptr}(\mathtt{int}) \sqcap \mathtt{void*}$.

The lack of an IR with well-defined semantics limits Van Emmerik's work, he had to use heuristics as
type patterns to recognize and propagate type/subtype relations.

\subsection{Improvement}
\noindent
Lee et al. in TIE~\cite{lee_tie_2011} had the same idea of using type lattice for type preciseness,
their deduction rules are more detail and support more cases
(e.g. calls and dynamic jumps) but basically similar to Van Emmerik's. For example,
the previously discussed assignment
\begin{equation*}
  p' = p + n
\end{equation*}
will generate $\vdash \mathtt{ptr}(T_{\beta}) <\colon \tau_{p'}$ where $T_{\beta}$ is
a type variable and $\tau_{p'}$ means type of $p'$, but $T_{\beta}$ is not free (never used outside
the assignment) then this constraint is equivalent with $\vdash p' \colon \mathtt{void*}$. The notable
improvement is the use of an IR named BIL (BAP Instruction Language), this makes the type analysis
simpler and more coherent.

\subsubsection*{Polymorphism}
The approaches discussed until now only consider basic cases of \emph{low-level polymorphism}, e.g.
adding a pointer to an integer may result in a pointer of the same type or not, but there are more.
For example, \texttt{mov} can freely move data between signed and unsigned values, or even a constant
can behaves as different types: zero is an integer, but it can be also a
\texttt{NULL} pointer. Another case is the indistinguishability between a pointer to a struct and
a pointer to the first field of this struct. All come from the low-level appearance of
\emph{type casting}, more details can be referenced in~\cite{siff_coping_1999}.

Noonan et al. handled these problems in Retypd~\cite{noonan_polymorphic_2016} by first
using subtyping in almost all derived constraints. The effect of data moving $x = y$ will be represented by
$\vdash \tau_{y} <\colon \tau_{x}$. More importantly, they proposed a
\emph{type capability} model: each type variable is attached with several labels representing it capabilities.
For example, the pointer dereference and assignment
\begin{equation*}
  x = *p
\end{equation*}
will result in $\vdash \tau_{p}.\mathtt{load} <\colon \tau_{x}$, means $p$ is a readable pointer
($\mathtt{.load}$ label), and
the type of the dereferenced value is a subtype of type of $x$. The labels on $\tau_{p}$ allows to
represent constraints on the inner structure of $p$ (if exists) and $p$ itself.
Retypd used lattices for subtype relations, and type analysis is proceeded on an IR, similar with TIE.

\subsection{Existing implementations}
Only Van Emmerik gives an open source implementation of type recovery in his Boomerang decompiler,
Lee et al and Noonan et al. do not. Published recently, Ghidra~\cite{noauthor_ghidra_nodate} is an
open source decompiler which has type recovery, we do not know how it works yet.
Other open source decompilers, Snowman~\cite{noauthor_snowman_nodate} or
RetDec~\cite{kroustek_retdec_2017}, do not seem focus much on this kind of analysis.
There are also commercial tools whose methods are not published,
most notably Hex-Rays~\cite{noauthor_hex-rays_nodate} and JEB~\cite{noauthor_jeb_nodate}.

\section{Type obfuscation}
\noindent
In this section, we present our proposal for type flattening obfuscation and techniques used in
our obfuscating compiler \emph{uCc} to obtain that notion. We
focus only on obfuscating scalar types (pointers, integers, but not floats), supporting aggregate types
(e.g. struct, nested struct) is still the ongoing work.

% Basically, our proposal for type obfuscation and bypassing binary type inference is based on the notion of
% \emph{type flattening} and the technique of corrupting the \emph{data-flow}, which are presented as follows.

\subsection{Notion}
\noindent
The type recovery approaches proposed different techniques to deal with the problem of
low-level polymorphism, but a common point
% of type recovery techniques
is to use some \emph{subtype lattice}
for the preciseness of inferred types. In the lattice, the bottom type $\bot$ means
that the variable violates some constraints in the type system~\cite{lee_tie_2011}.
Ideally, $\bot$ should not occur since in the worst case, the decompiler can simply
simulate the "weak" type system of the low-level language, we consider only $\top$.

The top type $\top$ means universal or any, intuitively if a variable is of type $\top$ then we only
know the most trivial information about its type.
% that we do not know anything about this type, or a variable of type $\top$ means it can be any type~\cite{lee_tie_2011}.
The idea of \emph{type flattening} is similar, removing useful information about type
of an object means making the type recovery algorithm infer the object's type as $\top$.
% that we cannot
% distinguish the type of some high-level object (variables, function signatures) from $\top$, i.e. we do not know
% any useful information about its type.

\begin{definition}
  A high-level object is called type flattened up to a type inference algorithm with subtyping
  if its type is inferred as $\top$ in the subtype lattice of the algorithm.
\end{definition}

\subsubsection*{Uncertainty}
Unsurprisingly, under some real world conditions, $\top$ type does not mean we do not know anything,
we actually know some properties. Recall that in our context, the binaries are disassemblable, function boundaries can be
recognized correctly.
Thus the binary, as our goal is to make it reusable, must respect the ABI (Application
Binary Interface). For example, AMD64 System V ABI specifies that the first parameter of
a function is passed via \texttt{rdi} register, thus in the worst case of the binary type
inference, the type of the first argument is $\mathtt{size64}$. The actual type may be
$\mathtt{char*}$, $\mathtt{signed32}$, $\mathtt{unsigned16}$, etc. but it is always
subtype of $\mathtt{size64}$ (see~\cref{fig:newtop}). This is actually what are being performed by some binary raising
projects~\cite{goodman_lifting_2018,yadavalli_raising_2019} and decompiler~\cite{durfina_detection_2012}.
\begin{figure}[h]
  \centering
  \begin{tikzcd}
    & \mathtt{size64} \arrow{dl}[sloped,above]{<\colon} \arrow{d}[sloped,above]{\colon>} \arrow{dr}[sloped, above]{\colon>} & \\
    \mathtt{char*} & \mathtt{signed32} & \mathtt{unsigned16}
  \end{tikzcd}
  \caption{$\top$ as $\mathtt{size64}$}
  \label{fig:newtop}
\end{figure}

\subsubsection*{Goal}
Our goal in type flattening obfuscation is to make any inferred type become $\top$. In our specific
context, under AMD SystemV ABI, it is $\mathtt{size64}$. For that goal, \emph{uCc} combines two
techniques: \emph{data-flow disrupting} and \emph{function signature masquerading}. The former
bypasses the intra-procedural data analysis, the later tricks the inter-procedural one.

\subsection{Data-flow disrupting}
\noindent
Though quite different about type systems, constraint generation rules and constraint solvers;
later type recovery techniques follow the \emph{data-flow based} approach proposed by Van Emmerik.
Actually, most of implementation code in TIE is for the data-flow analysis
and CFG building. Retypd uses an external abstract interpreter
which does the data-flow analysis, this interpreter contributes greatly to the
preciseness of the type inference.
%  results.

A direct technique for type flattening is to disrupt the data-flow analysis, that is done by
introducing \emph{pointer aliases}. Let's look at the
piece of code in~\cref{lst:directmov}, for illustration purpose we have used a pseudo-C syntax but only
put type annotation on the variables whose types are supposed to be already known.
\begin{lstlisting}[style={c},caption={Direct data movement},label={lst:directmov}]
foo(signed32 x) {
  p = &x;
  y = *p;
  return y;
}
\end{lstlisting}
Any type recovery method can find the return type of \texttt{foo}. Indeed,
with TIE: $\vdash p \colon \mathtt{ptr}(\mathtt{signed32})$ from the first assignment,
then the second infers $\vdash y \colon \mathtt{signed32}$. Retypd gives a slightly
different result $\vdash \mathtt{signed32} <\colon y$
where $y <\colon \mathtt{size32}$, which is also more precise.

In~\cref{lst:obfmov}, we insert an alias $q$ for $p$ to disrupt the data-flow.
TIE derives $\vdash y \colon \mathtt{size32}$, Retypd is not better
$\vdash \mathtt{size32} <\colon y$ where $\vdash y <\colon \mathtt{size32}$.
\begin{lstlisting}[style={c},caption={Data movement with pointer alias},label={lst:obfmov}]
foo(signed32 x) {
  p = &x;
  q = an alias of p;
  y = *q;
  return y;
}
\end{lstlisting}
In summary, before an use (which needs to be protected) of a
variable, \emph{uCc} \raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {1}}} creates a stack slot to store the variable,
\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {2}}} generates an alias for the stack slot,
\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {3}}} loads the variable from the alias.

\subsubsection*{Pointer alias generation}
Thanks to results about invertible \emph{permutation polynomials}~\cite{zhou_information_2007}, the
generation of pointer aliases become straightforward. Basically, for each case where a pointer needs to
be aliased, \emph{uCc} generates randomly an invertible polynomial MBA expression $P$ over
$\mathbb{Z}/2^n$ where $n$ is the machine word bit size ($n = 64$), and its inverse $Q = P^{-1}$
(see~\cref{fig:invertiblepolynomial} for an example of $P$ with degree 7 and its inverse $Q$),
the aliases of some value $v$ is $Q(P(v))$. The calculation of $Q(P(v))$ is embedded into the generated
binary code.

\subsection{Function signature masquerading}
\noindent
While types of local variables can be obfuscated by disrupting the data-flow, obfuscating
types of function parameters needs different techniques. For inter-procedural type analysis,
the data-flow disrupting still works because the type of passed arguments are already hidden: they
are local variables of the calling function. But for intra-procedural type analysis, we can still hide
the sign property (signed, unsigned) or whether they are pointers or not, but we cannot hide their
size (recall that our goal is to obtain $\top$ for all referred types).
% function parameters are one of type information sources; with the previous trick
That is because of the size of a function parameter can be detected
by looking at the register used to access this parameter inside the function. For example, if the first argument is of type
$\mathtt{int}$ (i.e. $\mathtt{signed32}$) then the register \texttt{edi} is used, not \texttt{rdi}.
The parameter size is masqueraded by the following techniques:

% \emph{uCc} masquerades the function parameter size using the following tricks.
\subsubsection*{Signature rewriting}
For each function, \emph{uCc} keeps an original copy of the signature but creates another signature
where size of each parameter is extended to $\mathtt{size64}$. The masqueraded signature is used
for any call to the function in the translation unit, so for from an external
(but in the translation unit) view, the function behaves as it has the masqueraded signature. The
original signature is used inside the function.

\subsubsection*{Trampoline block}
In the function, \emph{uCc} creates a trampoline as the pseudo-entry basic block, this trampoline uses
the masqueraded signature to retrieve the parameters but then convert them to the real ones using
the original signature. The conversion applies the data-flow disrupting to hide the source of
the parameters. The real parameters then passed into the real entry basic block.

\subsubsection*{Semantics gap and type erasure}
The techniques used for function signature masquerading have actually profited from \emph{semantics gap}
between the high-level and the machine language. In the high-level language, a function parameter
has some high-level type and the program will not type check if this type violates the type system
(e.g. passing an integer in a function whose the parameter type is pointer). But the ABI does not
have such a constraint, it simply states that, for example, the first parameter is passed via \texttt{rdi},
no matter what its type is. In another words, the semantics gap is an instance of \emph{type erasure}.

We can see also that the signature rewriting and inner trampoline profit the
low-level polymorphism to wrap a type by its supertype, this is exactly an inverse process of binary type
recovery which tries to unveil a type to get the underlying subtype.

% \subsection{Type flattening effect}
% \noindent
% \emph{uCc} combines the two techniques presented above for the goal of type flattening: any inferred
% type is $\mathtt{size64}$. The intra-procedural type analysis is bypassed by data-flow disrupting, while
% function signature masquerading tricks the inter-procedural type analysis.

\subsection{Other obfuscation tricks}
\noindent
\emph{uCc} implements also some supplemental techniques to augment its resilience from type analysis algorithms
and general deobfuscation efforts.

\subsubsection*{Split and merge}
To bypass the type constraints generated from $\mathtt{load}$/$\mathtt{store}$ operations in TIE, as well as
the derived types $\mathtt{.load}$/$\mathtt{.store}$ in Retypd. \emph{uCc}
may split the loading of a value into several loads, each of them retrieves a part of the value, then merges these
parts. This is a basic but useful obfuscation trick.

\subsubsection*{MBA rewriting}
\emph{uCc} uses some MBA rewriting rules to obfuscate basic arithmetic operations, $\mathtt{add}$,
$\mathtt{and}$, $\mathtt{or}$, $\mathtt{xor}$. The rules are taken from~\cite{eyrolles_obfuscation_2017}.
\begin{figure}[hb]
  \begin{align*}
    x + y &\rightarrow (x \wedge y) + (x \vee y) \\
    x \vee y &\rightarrow (x + y) - (x \wedge y) \\
    x \times y &\rightarrow (x \wedge y) \times (x \vee y) + (x \wedge \bar{y}) \times (\bar{x} \wedge y)
  \end{align*}
  \caption{Some rewriting rules used in \emph{uCc}}
\end{figure}


\subsubsection*{Code diversity}
\emph{uCc} is a \emph{probabilistic compiler}, the generation of pointer aliases is not the same over generated
binary codes: the coefficients and even the degree of invertible polynomials are generated randomly for
each run of \emph{uCC}. The number of split parts in a value loading is randomized, as well as the size of each part.

\section{Implementation}
\noindent
The open source implementation in Rust of \emph{uCc} is given at~\cite{ta_ucc_nodate}. The frontend is
implemented from scratch, the code generation part of the backend uses Cranelift~\cite{noauthor_cranelift_nodate}.
Beside the final result is an obfuscated ELF object file, \emph{uCc} has also several options, for example
JIT code generation, showing IR code, and selecting obfuscation level.

\subsubsection*{Notes}
\noindent
The principal goal of \emph{uCc} is type flattening obfuscation, but there is another requirement
that is the capability of evaluating the single effect of type flattening. Concretely,
we want that the functions in binaries generated by \emph{uCc} would be perfectly detectable,
disassemblable and decompilable (but with flattened types). For these purposes, we try to avoid any
other obfuscation tricks that may bring unwanted effects. Many
popular obfuscation techniques~\cite{banescu_tutorial_2018,collberg_surreptitious_2009}
(control-flow flattening, dead-code insertion, virtualization, code packing, self-modifying code, etc)
cannot be applied because they either protect the binaries from disassembling, or prevent the detection of
functions in the binary, as well as obfuscating the function control-flow graph.

% \subsection{Pointer alias generation with MBA}
% \noindent
% The open source implementation in Rust of \emph{uCc} is given at~\cite{ta_ucc_nodate}. The frontend is
% implemented from scratch, the code generation part of the backend

% The most "obfuscated" part of \emph{uCc} is data-flow disrupting.
% Thanks to results about invertible \emph{permutation polynomials}~\cite{zhou_information_2007}, the
% generation of pointer aliases become straightforward. Basically, for each case where a pointer needs to
% be aliased, \emph{uCc} generates randomly an invertible MBA
% polynomial $P$ over $\mathbb{Z}/2^n$ where $n$ is the machine word bit size ($n = 64$), and its
% inverse $Q = P^{-1}$ (see~\cref{fig:invertiblepolynomial} for an example of $P$ with degree 7 and its inverse $Q$), the aliases of
% some value $v$ is $Q(P(v))$. The calculation of $Q(P(v))$ is embedded into the generated binary code.

% 562949953421312, -6992785447134243183, 9007199254740992, 1125899906842624, 8796093022208, 4611686018427387904, 35184372088832, -9223372036854775808,

% -6116451243922554880, 8805192775852862065, -5341269158061408256, -4540754324296302592, -6409053278306304000, -4611686018427387904, -1711965992726298624, -9223372036854775808

\begin{figure*}[ht]
  \begin{align*}
    P(x) &= 562949953421312 - 6992785447134243183 \times x +  9007199254740992 \times x^2 + 1125899906842624 \times x^3 \\
         &+ 8796093022208 \times x^4 + 4611686018427387904 \times x^5 + 35184372088832 \times x^6 - 9223372036854775808 \times x^7 \\
    Q(x) &= -6116451243922554880 + 8805192775852862065 \times x - 5341269158061408256 \times x^2 - 4540754324296302592 \times x^3 \\
         &- 6409053278306304000 \times x^4 - 4611686018427387904 \times x^5 - 1711965992726298624 \times x^6 - 9223372036854775808 \times x^7 \\
  \end{align*}
  \caption{An invertible polynomial and its inverse generated by \emph{uCc}}
  \label{fig:invertiblepolynomial}
\end{figure*}

% \begin{align*}
%   P(x) &= 576460752303423488 + 8860833797731488269x + 137438953472x^2, \\
%   Q &= -2882303761517117440,
% \end{align*}

% \begin{equation*}

% \end{equation*}

\section{Evaluation}
\noindent
We test outputs of \emph{uCc} against some decompilers, \Cref{description} describes briefly
tested functions and their signatures in source codes, \Cref{flattening} shows results of
decompilers on binaries generated by \emph{uCc}.

\begin{table*}
	\begin{center}
		\caption{Functions and original types}\label{description}
		\begin{tabular}{|l|l|}
			\hline
			Description & Signature \\
			\hline
			identity & \texttt{int id(int)} \\
			\hline
			division & \texttt{int div(short, char)} \\
			\hline
			modular & \texttt{char mod(short, char)} \\
			\hline
			increase $p \leftarrow p + 1$ then dereference & \texttt{int inc\_deref(int *p)} \\
			\hline
			strlen  & \texttt{int slen(char *s)} \\
			\hline
			sdbm hash & \texttt{int sdbm(char *s)} \\
			\hline
			djb2 hash & \texttt{int djb2(char *s)} \\
			\hline
			sum of array $a$ & \texttt{long sum(short *a, int n)} \\
			\hline
			$n$-th fibonaci number (recursive impl.) & \texttt{int fibo(int n)} \\
			\hline
			num. of steps until $n \rightsquigarrow 1$ (Collatz's conj.)  & \texttt{int collatz(int n)} \\
			\hline
		\end{tabular}
	\end{center}
\end{table*}

\begin{sidewaystable}[ht]
  % \begin{table}
    % \begin{adjustwidth}{-6.21in}{-5.95in}
      % \begin{center}
        % \centering
        \caption{Type flattening effect}\label{flattening}
        % \begin{adjustbox}{max width=1.5\textwidth}
        \centering
        \scriptsize
        \begin{tabular}{|l|l|l|l|l|l|}
          \hline
          Original type & Hex-Rays & JEB & Ghidra & Snowman & RetDec \\
          \hline
          \texttt{int id(int)} & \texttt{int64 id(int64)} & \texttt{ulong id(ulong)} &
          \texttt{ulong id(void)} & \texttt{int64 id(int64)} & \texttt{int64 id(int64)} \\
          \hline
          \texttt{short div(short, char)} & \texttt{int64 div(uint64, uint64)} & \texttt{div\_t div(int, int)} &
          \texttt{div\_t div(int, int)} & \texttt{int64 div(int64, int64)} & \texttt{int64 div(int64, int64)} \\
          \hline
          \texttt{char mod(short, char)} & \texttt{int64 mod(int64, int64)} & \texttt{ulong mod(ulong, ulong)} &
          \texttt{ulong mod(void)} & \texttt{int64 mod(int64, int64)} & \texttt{int64 mod(int64, int64)} \\
          \hline
          \texttt{int inc\_deref(int*)} & \texttt{int64 inc\_deref(int64)} & \texttt{ulong inc\_deref(ulong)} &
          \texttt{ulong inc\_deref(undefined8)} & \texttt{int64 inc\_deref(uint64)} & \texttt{int64 int\_deref(int64)} \\
          \hline
          \texttt{int slen(char*)} & \texttt{int64 slen(int64)} & \texttt{ulong slen(ulong)} &
          \texttt{ulong slen(undefined8)} & \texttt{int64 slen(uint64)} & \texttt{int64 slen(int64)}\\
          \hline
          \texttt{int sdbm(char*)} & \texttt{int64 sdbm(uint64)} & \texttt{ulong sdbm(ulong)} &
          \texttt{ulong sdbm(undefined8)} & \texttt{int64 sdbm(uint64)} & \texttt{int64 sdbm(int64)} \\
          \hline
          \texttt{int djb2(char*)} & \texttt{int64 djb2(uint64)} & \texttt{ulong djb2(ulong)} &
          \texttt{ulong djb2(undefined8)} & \texttt{int64 djb2(uint64)} & \texttt{int64 djb2(int64)} \\
          \hline
          \texttt{long sum(short*, int)} & \texttt{int64 sum(int64, uint64)} & \texttt{ulong sum(ulong, ulong)} &
          \texttt{undefined8 sum(undefined8)} & \texttt{int64 sum(uint64, int64)} & \texttt{int64 sum(int64, int64)} \\
          \hline
          \texttt{int fibo(int)} & \texttt{int64 fibo(uint64)} & \texttt{ulong fibo(ulong)} &
          \texttt{ulong fibo(undefined8)} & \texttt{int64 fibo(int64)} & \texttt{int64 fibo(int64)} \\
          \hline
          \texttt{int collatz(int)} & \texttt{int64 collatz(int64)} & \texttt{ulong collatz(ulong)} &
          \texttt{ulong collatz(undefined8)} & \texttt{int64 collatz(int64)} & \texttt{int64 collatz(int64)} \\
          \hline
        \end{tabular}
      % \end{center}
    % \end{adjustwidth}
  % \end{table}
\end{sidewaystable}

% \begin{table*}
% 	\begin{adjustwidth}{-6.21in}{-5.95in}
% 		\begin{center}
% 			% \centering
% 			\caption{Type flattening effect}\label{flattening}
% 			% \begin{adjustbox}{max width=1.5\textwidth}
% 			\begin{tabular}{|l|l|l|l|l|}
% 				\hline
% 				Original type & Hex-Rays & JEB & Ghidra & Snowman \\
% 				\hline
% 				\texttt{int id(int)} & \texttt{int64 id(int64)} & \texttt{ulong id(ulong)} &
% 				\texttt{ulong id(void)} & \texttt{int64 id(int64)} \\
% 				\hline
% 				\texttt{short div(short, char)} & \texttt{int64 div(uint64, uint64)} & \texttt{div\_t div(int, int)} &
% 				\texttt{div\_t div(int, int)} & \texttt{int64\_t div(int64, int64)} \\
% 				\hline
% 				\texttt{char mod(short, char)} & \texttt{int64 mod(int64, int64)} & \texttt{ulong mod(ulong, ulong)} &
% 				\texttt{ulong mod(void)} & \texttt{int64 mod(int64, int64)} \\
% 				\hline
% 				\texttt{int inc\_deref(int*)} & \texttt{int64 inc\_deref(int64)} & \texttt{ulong inc\_deref(ulong)} &
% 				\texttt{ulong inc\_deref(undefined8)} & \texttt{int64 inc\_deref(uint64)} \\
% 				\hline
% 				\texttt{int slen(char*)} & \texttt{int64 slen(int64)} & \texttt{ulong slen(ulong)} &
% 				\texttt{ulong slen(undefined8)} & \texttt{int64 slen(uint64)} \\
% 				\hline
% 				\texttt{int sdbm(char*)} & \texttt{int64 sdbm(uint64)} & \texttt{ulong sdbm(ulong)} &
% 				\texttt{ulong sdbm(undefined8)} & \texttt{int64 sdbm(uint64)} \\
% 				\hline
% 				\texttt{int djb2(char*)} & \texttt{int64 djb2(uint64)} & \texttt{ulong djb2(ulong)} &
% 				\texttt{ulong djb2(undefined8)} & \texttt{int64 djb2(uint64)} \\
% 				\hline
% 				\texttt{long sum(short*, int)} & \texttt{int64 sum(int64, uint64)} &
% 				\texttt{ulong sum(ulong, ulong)} & \texttt{undefined8 sum(undefined8)} & \texttt{int64 sum(uint64, int64)} \\
% 				\hline
% 				\texttt{int fibo(int)} & \texttt{int64 fibo(uint64)} & \texttt{ulong fibo(ulong)} &
% 				\texttt{ulong fibo(undefined8)} & \texttt{int64 fibo(int64)} \\
% 				\hline
% 				\texttt{int collatz(int)} & \texttt{int64 collatz(int64)} & \texttt{ulong collatz(ulong)} &
% 				\texttt{ulong collatz(undefined8)} & \texttt{int64 collatz(int64)} \\
% 				\hline
% 			\end{tabular}
% 		\end{center}
% 	\end{adjustwidth}
% \end{table*}

\section{Related work}
\noindent
there is still no explicit effort in obfuscating
high-level types. There would be several reasons for this lack of effort.

\emph{First}, type obfuscation is unsurprisingly a side effect of data or control flow obfuscation.
Indeed, type reconstruction algorithms need data and control flow to build type constraints,
if any of them is hidden
then the algorithms cannot work correctly. Or if the function boundary is not found
(because of anti-disassembly tricks, for example), then high-level objects cannot be recognized.
\emph{Second}, high-level types seem too coarse to be worthy
of being protected, in many cases just knowing certain values of the input which make the program
exploitable is enough. But knowledge about types expands attack surfaces because more analysis
can be proceeded, beside decompilation see the survey~\cite{caballero_type_2016} for a
more complete list.

\section*{Acknowledgment}
\noindent
Thanks to my wife.

% but type analysis is proceeded on IR named BIL (BAP Instruction Language).

% This makes the type analysis more flexible:
% \emph{type variables} are used not only for annotating unknown types but also on operators
% between them. Let's consider the following example:
% \begin{equation*}
%   p' = p + n; \thickspace *p' = v_{\mathtt{signed}}; \thickspace v' = *p';
% \end{equation*}
% The type equations used by Van Emmerik do not allow to recover precisely the type of $v'$: the
% first two assignments derive $\vdash p' \colon \mathtt{ptr}(\mathtt{int}_{\mathtt{signed}})$; but on
% the last one, the type of the sub-expression $p'$ is recalculated, and it backs to the first
% $\vdash p' \colon \mathtt{void*}$, thus $\vdash v' \colon \mathtt{int}$. Lee et al. use
% a type variable $T_{\alpha}$ for the pointer type $\vdash p' <\colon \mathtt{ptr}(T_{\alpha})$
% in the first assignment, the second derives $T_{\alpha} = \mathtt{int}_{\mathtt{signed}}$ and
% the last gives $\vdash v' \colon \mathtt{int}_{\mathtt{signed}}$.

% Since the existence of obfuscation, code analysis has been also evolved

% This document was successfully compiled into a compliant pdf file by
% the Program Chairs with the command

% \begin{center}\fbox{\texttt{latexmk -pdf
%   eurosp-2020-template.tex}}
% \end{center}

% \noindent using Latexmk version 4.55 (17 Jan 2018),
% which called pdfTeX 3.14159265-2.6-1.40.19 (TeX Live 2018). We also
% successfully compiled on MiKTeX-pdfTeX 2.9.7029 (1.40.20) (MiKTeX
% 2.9.7050 64-bit).  The above command was issued in a directory
% containing the following files: \texttt{IEEEtran.cls,
%   eurosp-2020-template.tex, fig1.png}.

% This document is a model and a set of instructions. Please read the
% instructions at least once and comply with them. Please do not change
% the \verb-\documentclass- options; specifically, stick to the A4 page
% format, \emph{not} US Letter. Please observe the conference page
% limits. Consult the Call For Papers if in doubt, which you'll find on
% the conference website at
% \url{https://www.ieee-security.org/TC/EuroSP2020/}. Write to the
% Program Chairs at
% \href{mailto:eurosp2020-pc-chairs@ieee-security.org}{eurosp2020-pc-chairs@ieee-security.org}
% if you still have problems.

% If you feel the urge to upload your draft to ArXiv before submitting,
% please leave the \verb-\thanks{}- footnote as is. Otherwise
% \textcolor{red}{remove the sentence ``A preprint of this paper has
%   been deposited on ArXiv''} from it. See the ``Anonymous Submission''
% section of the CFP for details.


% \section{Ease of Use}

% \subsection{Maintaining the Integrity of the Specifications}

% The IEEEtran class file is used to format your paper and style the text. All margins,
% column widths, line spaces, and text fonts are prescribed; please do not
% alter them. You may note peculiarities. For example, the head margin
% measures proportionately more than is customary. This measurement
% and others are deliberate, using specifications that anticipate your paper
% as one part of the entire proceedings, and not as an independent document.
% Please do not revise any of the current designations.

% \section{Prepare Your Paper Before Styling}
% Before you begin to format your paper, first write and save the content as a
% separate text file. Complete all content and organizational editing before
% formatting. Please note sections \ref{AA}--\ref{SCM} below for more information on
% proofreading, spelling and grammar.

% Keep your text and graphic files separate until after the text has been
% formatted and styled. Do not number text heads---{\LaTeX} will do that
% for you.

% \subsection{Abbreviations and Acronyms}\label{AA}
% Define abbreviations and acronyms the first time they are used in the text,
% even after they have been defined in the abstract. Abbreviations such as
% IEEE, SI, MKS, CGS, ac, dc, and rms do not have to be defined. Do not use
% abbreviations in the title or heads unless they are unavoidable.

% \subsection{Units}
% \begin{itemize}
% \item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
% \item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
% \item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
% \item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
% \end{itemize}

% \subsection{Equations}
% Number equations consecutively. To make your
% equations more compact, you may use the solidus (~/~), the exp function, or
% appropriate exponents. Italicize Roman symbols for quantities and variables,
% but not Greek symbols. Use a long dash rather than a hyphen for a minus
% sign. Punctuate equations with commas or periods when they are part of a
% sentence, as in:
% \begin{equation}
% a+b=\gamma\label{eq}
% \end{equation}

% Be sure that the
% symbols in your equation have been defined before or immediately following
% the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at
% the beginning of a sentence: ``Equation \eqref{eq} is . . .''

% \subsection{\LaTeX-Specific Advice}

% Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
% of ``hard'' references (e.g., \verb|(1)|). That will make it possible
% to combine sections, add equations, or change the order of figures or
% citations without having to go through the file line by line.

% Please don't use the \verb|{eqnarray}| equation environment. Use
% \verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
% environment leaves unsightly spaces around relation symbols.

% Please note that the \verb|{subequations}| environment in {\LaTeX}
% will increment the main equation counter even when there are no
% equation numbers displayed. If you forget that, you might write an
% article in which the equation numbers skip from (17) to (20), causing
% the copy editors to wonder if you've discovered a new method of
% counting.

% {\BibTeX} does not work by magic. It doesn't get the bibliographic
% data from thin air but from .bib files. If you use {\BibTeX} to produce a
% bibliography you must send the .bib files.

% {\LaTeX} can't read your mind. If you assign the same label to a
% subsubsection and a table, you might find that Table I has been cross
% referenced as Table IV-B3.

% {\LaTeX} does not have precognitive abilities. If you put a
% \verb|\label| command before the command that updates the counter it's
% supposed to be using, the label will pick up the last counter to be
% cross referenced instead. In particular, a \verb|\label| command
% should not go before the caption of a figure or a table.

% Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
% will not stop equation numbers inside \verb|{array}| (there won't be
% any anyway) and it might stop a wanted equation number in the
% surrounding equation.

% \subsection{Some Common Mistakes}\label{SCM}
% \begin{itemize}
% \item The word ``data'' is plural, not singular.
% \item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
% \item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
% \item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
% \item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
% \item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
% \item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
% \item Do not confuse ``imply'' and ``infer''.
% \item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
% \item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
% \item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
% \end{itemize}
% An excellent style manual for science writers is \cite{b7}.

% \subsection{Authors and Affiliations}
% \textbf{The class file is designed for, but not limited to, six authors.} A
% minimum of one author is required for all conference articles. Author names
% should be listed starting from left to right and then moving down to the
% next line. This is the author sequence that will be used in future citations
% and by indexing services. Names should not be listed in columns nor group by
% affiliation. Please keep your affiliations as succinct as possible (for
% example, do not differentiate among departments of the same organization).

% \subsection{Identify the Headings}
% Headings, or heads, are organizational devices that guide the reader through
% your paper. There are two types: component heads and text heads.

% Component heads identify the different components of your paper and are not
% topically subordinate to each other. Examples include Acknowledgments and
% References and, for these, the correct style to use is ``Heading 5''. Use
% ``figure caption'' for your Figure captions, and ``table head'' for your
% table title. Run-in heads, such as ``Abstract'', will require you to apply a
% style (in this case, italic) in addition to the style provided by the drop
% down menu to differentiate the head from the text.

% Text heads organize the topics on a relational, hierarchical basis. For
% example, the paper title is the primary text head because all subsequent
% material relates and elaborates on this one topic. If there are two or more
% sub-topics, the next level head (uppercase Roman numerals) should be used
% and, conversely, if there are not at least two sub-topics, then no subheads
% should be introduced.

% \subsection{Figures and Tables}
% \paragraph{Positioning Figures and Tables} Place figures and tables at the top and
% bottom of columns. Avoid placing them in the middle of columns. Large
% figures and tables may span across both columns. Figure captions should be
% below the figures; table heads should appear above the tables. Insert
% figures and tables after they are cited in the text. Use the abbreviation
% ``Fig.~\ref{fig}'', even at the beginning of a sentence.

% \begin{table}[htbp]
% \caption{Table Type Styles}
% \begin{center}
% \begin{tabular}{|c|c|c|c|}
% \hline
% \textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
% \cline{2-4}
% \textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
% \hline
% copy& More table copy$^{\mathrm{a}}$& &  \\
% \hline
% \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
% \end{tabular}
% \label{tab1}
% \end{center}
% \end{table}

% \begin{figure}[htbp]
% \centerline{\includegraphics[width=0.8\columnwidth]{fig1.png}}
% \caption{Example of a figure caption.}
% \label{fig}
% \end{figure}

% Figure Labels: Use 8 point Times New Roman for Figure labels. Use words
% rather than symbols or abbreviations when writing Figure axis labels to
% avoid confusing the reader. As an example, write the quantity
% ``Magnetization'', or ``Magnetization, M'', not just ``M''. If including
% units in the label, present them within parentheses. Do not label axes only
% with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization
% \{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of
% quantities and units. For example, write ``Temperature (K)'', not
% ``Temperature/K''.

% \section*{Acknowledgment}

% The preferred spelling of the word ``acknowledgment'' in America is without
% an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B.
% G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor
% acknowledgments in the unnumbered footnote on the first page.

\printbibliography

% \section*{How to write the references}

% Please number citations consecutively within brackets \cite{b1}. The
% sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference
% number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at
% the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

% Number footnotes separately in superscripts. Place the actual footnote at
% the bottom of the column in which it was cited. Do not put footnotes in the
% abstract or reference list. Use letters for table footnotes.

% Unless there are six authors or more give all authors' names; do not use
% ``et al.''. Papers that have not been published, even if they have been
% submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers
% that have been accepted for publication should be cited as ``in press'' \cite{b5}.
% Capitalize only the first word in a paper title, except for proper nouns and
% element symbols.

% For papers published in translation journals, please give the English
% citation first, followed by the original foreign-language citation \cite{b6}.

% \begin{thebibliography}{00}
% \bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
% \bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
% \bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
% \bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
% \bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
% \bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
% \bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
% \end{thebibliography}

% \appendices

% \section{Experimental data}
% \lipsum[1-4]
% \section{Theorem proofs}
% \lipsum[5-6]

% \vspace{12pt}
% \color{red}
% IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
